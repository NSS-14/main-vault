
The training algorithms for the linear regression and logistic regression used the gradients of an error functions. We can give the perceptron a rule of training with gradients, considering the loss function for the training set:

$$J(w) = \sum_{i:\hat y^{(i)} \neq y^{(i)}} \hat y^{(i)} w^t \cdot x^{(i)}$$

Where the set where the summation is made, is those cases from training set S, where the perceptron has errors of classification.

Obviously:

- when the perceptron makes correct clasification for thw whole training set, the loss function J has the value 0, because the sum is made on an empty set.
- for a case of $\hat y^{(i)} \neq y^{(i)}$, we have that $\hat y^{(i)} w^t \cdot x^{(i)} > 0$;

For a any case of $\hat y^{(i)} \neq y^{(i)}$, the gradient of $\hat y^{(i)} w^t \cdot x^{(i)}$ with respect to w is:

$$\nabla_w [\hat y^{(i)} w^t \cdot x^{(i)}] = \hat y^{(i)} \nabla_w[w^t \cdot x^{(i)}] = \hat y^{(i)} \cdot x^{(i)}$$

If apply the gradient descent algorithm for the current entry, it means that we modify the actual weights with:

$$-\alpha \cdot \nabla_w [\hat y^{(i)} w^t \cdot x^{(i)}] = \alpha(-\hat y^{(i)})x^{(i)} = \alpha y^{(i)} x^{(i)}$$

We can see a difference between the perceptron's algorithm and the algorithms from the linear and logistic regression: at those from the end, the loss function is calculated on the whole traing set, on the other hand, for the pereceptron, the error is calculated and the gradient is applied just for the cases where the classification failed. Modifing the algorithm of the perceptron using the agregated function and the gradients is instant. We preffer the previous algorithm because is more classic.
