## Topics:
#LinearRegression;
#CardinalityOfTheTrainingDataSetNotation : [[2.1 Examples and notations#^2eb424]];
#InputVectorNotation : [[2.1 Examples and notations#^72c918]];
#OutputVectorNotation : [[2.1 Examples and notations#^2bd83f]];
#TheTrainingDataSetNotation : [[2.1 Examples and notations#The whole training set]];
#EstimatedValueNotation : [[2.1 Examples and notations#More notations]];
#LinearRegressionModelEquation : [[2.1 Examples and notations#The shape of the model]];

## Notes:
### Example:
The regression models can learn and predict numerical values from an infinite set. For example, we want to predict the cost of an apartament, given it's area. Some previous data is known about the such apartaments sells, like in the above table. For the simplity, we suppose that the only feature of an apartament it is it's area, in square meaters.
![[Draft_09-08-2023_07.42.01.excalidraw]]

Based on this data, we will construct a function which will aproximate the price (real number) for other apartaments.

Suppose that it is desired to estimate the value of an apartament with area s = 80 $m^2$, without having this example in the training data set. We will have to guess the price. To do it, it is drawn a line which has to aproximate as best as possible the cloud of dots which represents the appartaments. The value estimated by the model for an apartament with an area a, it is simply found. It is drawn an vertical which goes throw the point of coordonates (a, 0), and we find the intersection with the model's line. The value of y(a) which corresponds with this intersection dot is the estimated price by the model, for that area.
![[Draft_09-08-2023_07.52.35.excalidraw]]

The model that predicts the price of an apartament based on it's area:
$$\text{estimated\_price} = a \cdot area + b$$
, where a and b are real coefficients that will get determined through the learning process. The coefficient a is called the slope, and b is the intercept. Of course, the model can use polynomial form with a grade higher than 1, or models that are localy linears, artificial neural networks, etc. The choice for the best model for a data set is a problem by itself. The linear model is preffered because, in practice, it is a good starting point, and the simple models are recomanded to be tested first. Bonus, the linear model it is easy to understand, if the area gets incresed by 1 unit, then the price increases by a euros. The value for b represents the starting price, there is no apartament which is less than b euros.

### Notations:
- m - representing the amount of recordings or pairs from the data set; ^2eb424
- $x^{(i)}$ - represent m entry vectors, $1 \le i \le m$, such vector contains n numerical values, called features: $x^{(i)} = (x_1^{(i)}, x_2^{(i)}, \text{...}, x_n^{(i)})^t$ : area, number of rooms, number of bathrooms, etc. The attributes $x_j$ are also called predictible variables; ^72c918
- $y^{(i)}$ - represent the output variable (ground truth) belonging to the value $x^{(i)}$; ^2bd83f

### The whole training set:
The pair i from the training data set S is ($x^{(i)}, y^{(i)}$), $1 \le i \le m$. The whole training set is written as:
$$ S = \{ (x^{(i)}, y^{(i)}) \space | \space 1 \le i \le m \}$$

## The working flow of the autonom learning:
![[Draft_10-08-2023_11.20.47.excalidraw]]

### More notations:
After the training is done, the resulted model gets an input vector x (for our example, the area of an apartament) and he will compute the estimated value for that input, denoted with $\hat{y}$ (the price, for our example). In formal notation, we have the equation:
$$\hat{y} = h(x)$$
The notation that has the hat above is used for the values that are estimated by the model h.

### The shape of the model:
For the example with the apartaments, we have supposed that the price grows in relation with the area, in a linear manner. If this is the case, the model h can look like this:
$$h(x) = h_\theta(x) = \theta_0 + \theta_1 \cdot x = \hat{y}$$
Where the index of h is the column vector of coefficients $\theta = (\theta_0, \theta_1)^t$.

This model h, it is called linear regression with one variable, or univariabled linear regression. It is possible that, following the surface of an apartament (the only input value considered until now), we can have additional input features about an apartament. In this case, the model will be called multivariabled. The coefficients $\theta_0, \theta_1$ are also called parameters of the prediction model, and they are determined in the learning phase. The model can also be written as:
$$h_\theta(x) = \theta_0 \cdot 1 + \theta_1 \cdot x = \theta_0 \cdot x_0 + \theta_1 \cdot x_1 = x^t \cdot \theta = \hat{y}$$
Where $x_0$ is always 1, $x_1$ is x, the vector $\theta = (\theta_0, \theta_1)^t$, and the vector $x = (x_0, x_1)^t$. The fact that, $x_0 = 1$, makes it possible for a free term to exist ($\theta_0$) in the linear model. This makes the regression line not necesary cross the origin of the graph (0, 0).

### Univariated linear regression graph:
![[Draft_10-08-2023_12.19.34.excalidraw]]
